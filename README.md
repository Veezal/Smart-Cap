<h1> Smart Cap </h1>
The Smart Cap is a closed-loop control system that utilizes computer vision and natural language processing techniques to provide audio feedback to users about their surrounding environment. This repository contains the code and resources for implementing the image-to-text conversion.
<br>
 <H3>Over View</H3>
 The image-to-text conversion module of the Smart Cap system is responsible for extracting meaningful information from captured images and generating descriptive captions using a CNN-LSTM model.
 

<h3>Dataset</h3>
The Smart Cap system uses the Flickr30k dataset for training and evaluation. The dataset contains images and corresponding captions. You can download the dataset from [Flickr30k Dataset](https://www.kaggle.com/datasets/adityajn105/flickr30k).

<h3>Results</h3>
After running the code, the system will generate captions for the test images. The predicted captions can be compared with the actual captions from the dataset. The code also calculates the BLEU-1, BLEU-2, BLEU-3, and BLEU-4 scores to evaluate the quality of the generated captions.
